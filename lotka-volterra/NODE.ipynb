{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUtix5oO1hZa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "from numpy import sin, cos\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "solver = scipy.integrate.solve_ivp\n",
    "\n",
    "seed = 12\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.determinstic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNbE8mFW6lHD"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "BATCH_size = 1000\n",
    "\n",
    "dftarget = pd.read_csv(\"./data/target.csv\", header=None, dtype=np.float32)\n",
    "dfinput = pd.read_csv(\"./data/input.csv\", header=None, dtype=np.float32)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dfinput.values, dftarget.values, test_size=0.2)\n",
    "\n",
    "# train data\n",
    "data_train = data_utils.TensorDataset(torch.tensor(X_train), torch.tensor(Y_train))\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_size, shuffle=True)\n",
    "\n",
    "# test data\n",
    "data_test = data_utils.TensorDataset(torch.tensor(X_test), torch.tensor(Y_test))\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=BATCH_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdXd4_3_-nmQ"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-YlCua3H-qfx"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super(MLP, self).__init__()\n",
    "    self.l1 = nn.Linear(input_size, hidden_size)\n",
    "    self.l2 = nn.Linear(hidden_size, hidden_size)\n",
    "    self.l3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.l1(x)\n",
    "    x = torch.tanh(x)\n",
    "    x = self.l2(x)\n",
    "    x = torch.tanh(x)\n",
    "    x = self.l3(x)\n",
    "    return x\n",
    "\n",
    "  def fvec(self, t, x):\n",
    "    return self.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d1Ev3hUN-uSp"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "input_size = 2\n",
    "output_size = 2\n",
    "hidden_size = 200\n",
    "num_trials = 10\n",
    "stats = {'train_loss': [], 'eval_loss': [], 'computation_time': []}\n",
    "\n",
    "for trial in range(num_trials):\n",
    "  mlp_net = MLP(input_size, hidden_size, output_size).to(device)\n",
    "\n",
    "  num_epochs = 2000\n",
    "  criterion = nn.MSELoss()\n",
    "  optimizer = optim.Adam(params=mlp_net.parameters(), lr=0.001)\n",
    "\n",
    "  history_loss = []\n",
    "  history_eval = []\n",
    "  history_acc = []\n",
    "  startt = time.time()\n",
    "  cnt = 0\n",
    "  for epoch in range(num_epochs):\n",
    "    mlp_net.train()\n",
    "    total_loss = 0.0\n",
    "    eval_loss = 0.0\n",
    "    for i,(data,target) in enumerate(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "      output = mlp_net(data.to(device))\n",
    "      target = target.to(device)\n",
    "\n",
    "      loss = criterion(output,target)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      total_loss = total_loss+loss.cpu().item()\n",
    "      cnt = cnt + 1\n",
    "    total_loss = total_loss/cnt\n",
    "    num_correct = 0\n",
    "    num_data = 0\n",
    "    mlp_net.eval()\n",
    "    eval_loss = 0.0\n",
    "    cnt = 0\n",
    "    for i,(data,target) in enumerate(test_loader):\n",
    "      output = mlp_net(data.to(device))\n",
    "      target = target.to(device)\n",
    "\n",
    "      eval_loss = eval_loss+criterion(output,target).cpu().item()\n",
    "      cnt = cnt + 1\n",
    "    eval_loss = eval_loss/cnt\n",
    "    \n",
    "    history_loss.append(total_loss)\n",
    "    history_eval.append(eval_loss)\n",
    "  print(\"{}/{} training loss:{},evaluation loss:{}\".format(epoch+1,num_epochs,total_loss,eval_loss))\n",
    "  path = \"./model/node_lv_{}\".format(trial)\n",
    "  torch.save(mlp_net.state_dict(), path)\n",
    "  stats['train_loss'].append(total_loss)\n",
    "  stats['eval_loss'].append(eval_loss)\n",
    "  stats['computation_time'].append(time.time() - startt)\n",
    "\n",
    "print(\"train_loss:{}, std: {}\".format(np.mean(stats['train_loss']), np.std(stats['train_loss'])))\n",
    "print(\"test_loss:{}, std: {}\".format(np.mean(stats['eval_loss']), np.std(stats['eval_loss'])))\n",
    "print(\"computation_time:{}, std: {}\".format(np.mean(stats['computation_time']), np.std(stats['computation_time'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.read_csv(\"./data/A.csv\", header=None, dtype=np.float32)\n",
    "B = pd.read_csv(\"./data/B.csv\", header=None, dtype=np.float32)\n",
    "A = np.mat(A)\n",
    "B = np.mat(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation\n",
    "# parameters\n",
    "a11 = 1.0\n",
    "a12 = -1.0\n",
    "a21 = -1.0\n",
    "a22 = 1.0\n",
    "eq_error = []\n",
    "\n",
    "for trial in range(num_trials):\n",
    "  mlp_net.load_state_dict(torch.load(\"./model/node_lv_{}\".format(trial), map_location=\"cpu\"))\n",
    "  mlp_net.eval()\n",
    "  teval = torch.linspace(0.0,30.0,100)\n",
    "  x0 = np.random.uniform(low=0.0, high=1.0, size=2)\n",
    "  #x0 = (0.41527075, 0.1356582)\n",
    "  print(x0)\n",
    "  dt = teval[1]-teval[0]\n",
    "  teval = teval.detach().cpu().numpy()\n",
    "  A = torch.tensor(A, dtype=torch.float32)\n",
    "  B = torch.tensor(B, dtype=torch.float32)\n",
    "  mlp_net.eval()\n",
    "  mlp_net.cpu()\n",
    "  def fvec_np(x,t):\n",
    "      tx = torch.tensor(x, dtype=torch.float).unsqueeze(0)\n",
    "      x = torch.matmul(tx, torch.inverse(B))\n",
    "      output = mlp_net.forward(x).squeeze(0)\n",
    "      output = torch.matmul(A, output)\n",
    "      output = output.squeeze(0)\n",
    "      return output.detach().cpu().numpy()\n",
    "  res = scipy.integrate.odeint(fvec_np,x0,teval)\n",
    "  plt.plot(teval,res[:,0])\n",
    "  plt.plot(teval,res[:,1])\n",
    "  plt.show()\n",
    "\n",
    "  energy = -a21*np.log(res[:,0])-a22*res[:,0]+a11*np.log(res[:,1])+a12*res[:,1]\n",
    "  energy_error=energy[99]-energy[0]\n",
    "  print(\"energy_error{}:{}\".format(trial,energy_error))\n",
    "  plt.plot(energy)\n",
    "  plt.show()\n",
    "\n",
    "  eq_error.append(energy_error)\n",
    "\n",
    "print(\"eq_error:{}\".format(eq_error))\n",
    "print(\"eq_error:{}, std: {}\".format(np.mean(np.abs(eq_error)), np.std(eq_error)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "J1Cgdeyl_J45",
    "outputId": "781cf863-fc67-4cfc-c136-d472c3c475e5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "# parameters\n",
    "a11 = 1.0\n",
    "a12 = -1.0\n",
    "a21 = -1.0\n",
    "a22 = 1.0\n",
    "\n",
    "def func(t, state):\n",
    "  dvdt = np.zeros_like(state)\n",
    "  dvdt[0] = a11*state[0] + a12*state[0]*state[1]\n",
    "  dvdt[1] = a21*state[1] + a22*state[0]*state[1]\n",
    "  return dvdt\n",
    "\n",
    "#ã€€the time grid\n",
    "M = 100\n",
    "tend = 30.0\n",
    "t_eval = np.linspace(0,tend,M)\n",
    "dt = t_eval[1]-t_eval[0]\n",
    "num = 1000\n",
    "state = []\n",
    "for i in range(1):\n",
    "  s = (0.41527075, 0.1356582)\n",
    "  state.append(s)\n",
    "\n",
    "q1 = []\n",
    "q2 = []\n",
    "\n",
    "flag = False\n",
    "for i in range(1):\n",
    "  sol = solver(func, [0, tend], state[i], t_eval=t_eval)\n",
    "  tval = sol['t']\n",
    "  q1 = sol['y'][0]\n",
    "  q2 = sol['y'][1]\n",
    "  plt.plot(tval, q1, 'steelblue')\n",
    "  plt.plot(tval, q2, 'orange')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "node (lv)(AB).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
