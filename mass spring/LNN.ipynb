{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3851,
     "status": "ok",
     "timestamp": 1621404882578,
     "user_tz": -540
    },
    "id": "QaYW5xQAhz7Y"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "from numpy import sin, cos\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "solver = scipy.integrate.solve_ivp\n",
    "\n",
    "seed = 3\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.determinstic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24161,
     "status": "ok",
     "timestamp": 1621404902893,
     "user_tz": -540
    },
    "id": "kupGW9hFh6nW",
    "outputId": "f467c793-f30e-4596-cae7-66380754a629",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "BATCH_size = 1000\n",
    "\n",
    "dftarget = pd.read_csv(\"./data/target.csv\", header=None, dtype=np.float32)\n",
    "dfinput = pd.read_csv(\"./data/input.csv\", header=None, dtype=np.float32)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dfinput.values, dftarget.values, test_size=0.2)\n",
    "\n",
    "# train data\n",
    "data_train = data_utils.TensorDataset(torch.tensor(X_train), torch.tensor(Y_train))\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_size, shuffle=True)\n",
    "\n",
    "# test data\n",
    "data_test = data_utils.TensorDataset(torch.tensor(X_test), torch.tensor(Y_test))\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=BATCH_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4729,
     "status": "ok",
     "timestamp": 1621404906943,
     "user_tz": -540
    },
    "id": "ZbV6ylW1iG1P"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1621405020399,
     "user_tz": -540
    },
    "id": "lqa-i5cjiJCK"
   },
   "outputs": [],
   "source": [
    "class LNN(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super().__init__()\n",
    "        self.L = L\n",
    "    def forward(self, x):\n",
    "        with torch.set_grad_enabled(True):\n",
    "            self.n = n = x.shape[1]//2\n",
    "            qqd = x.requires_grad_(True)\n",
    "            L = self._lagrangian(qqd).sum()\n",
    "            J = grad(L, qqd, create_graph=True)[0] ;\n",
    "            DL_q, DL_qd = J[:,:n], J[:,n:]\n",
    "            DDL_qd = []\n",
    "            for i in range(n):\n",
    "                J_qd_i = DL_qd[:,i][:,None]\n",
    "                H_i = grad(J_qd_i.sum(), qqd, create_graph=True)[0][:,:,None]\n",
    "                DDL_qd.append(H_i)\n",
    "            DDL_qd = torch.cat(DDL_qd, 2)\n",
    "            DDL_qqd, DDL_qdqd = DDL_qd[:,:n,:], DDL_qd[:,n:,:]\n",
    "            T = torch.einsum('ijk, ij -> ik', DDL_qqd, qqd[:,n:])\n",
    "            qdd = torch.einsum('ijk, ij -> ik', DDL_qdqd.inverse(), DL_q - T)\n",
    "        return torch.cat([qqd[:,self.n:], qdd], 1)\n",
    "    def _lagrangian(self, qqd):\n",
    "        return self.L(qqd)    \n",
    "    def energy(self, qqd):\n",
    "        n = qqd.shape[1]//2\n",
    "        lag = self.L(qqd)\n",
    "        lag_sum = lag.sum()\n",
    "        lag_grad = grad(lag_sum, qqd, create_graph=False)[0] ;\n",
    "        DL_q, DL_qd = lag_grad[:,:n], lag_grad[:,n:]\n",
    "        dq = qqd[:,n:]\n",
    "        inner_prod = (dq*DL_qd).sum(1, keepdim=True)\n",
    "        energy = lag - inner_prod\n",
    "        return energy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1605,
     "status": "ok",
     "timestamp": 1621405021571,
     "user_tz": -540
    },
    "id": "SgFkxwWQiLdf"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "input_size = 4\n",
    "hidden_size = 200\n",
    "output_size = 1\n",
    "num_trials = 10\n",
    "stats = {'train_loss': [], 'eval_loss': [], 'computation_time': []}\n",
    "\n",
    "for trial in range (num_trials):\n",
    "  l_nn = LNN(nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size,output_size))\n",
    "         ).to(device)\n",
    "\n",
    "  num_epochs = 2000\n",
    "\n",
    "  criterion = nn.MSELoss()\n",
    "\n",
    "  optimizer = optim.Adam(params=l_nn.parameters(),lr=0.0001)\n",
    "\n",
    "  history_loss = []\n",
    "  history_eval = []\n",
    "  history_acc = []\n",
    "  cnt = 0\n",
    "  startt = time.time()\n",
    "  for epoch in range(num_epochs):\n",
    "    l_nn.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    eval_loss = 0.0\n",
    "    cnt = 0\n",
    "    for i,(data,target) in enumerate(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "      output = l_nn.forward(data.to(device))\n",
    "\n",
    "      loss = criterion(output,target.to(device))\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      total_loss = total_loss+loss.cpu().item()\n",
    "      cnt = cnt + 1\n",
    "    total_loss = total_loss/cnt\n",
    "      \n",
    "\n",
    "    num_correct = 0\n",
    "    num_data = 0\n",
    "    l_nn.eval()\n",
    "    eval_loss = 0.0\n",
    "    cnt = 0\n",
    "    for i,(data,target) in enumerate(test_loader):\n",
    "      output = l_nn.forward(data.to(device))\n",
    "      eval_loss = eval_loss+criterion(output,target.to(device)).cpu().item()\n",
    "      cnt = cnt + 1\n",
    "    eval_loss = eval_loss/cnt\n",
    "  \n",
    "    history_loss.append(total_loss)\n",
    "    history_eval.append(eval_loss)\n",
    "    \n",
    "    if total_loss == np.min(history_loss):\n",
    "      min_total_loss_in_tl = total_loss\n",
    "      min_evaluation_loss_in_tl = eval_loss\n",
    "      min_train_index = epoch+1\n",
    "\n",
    "    if eval_loss == np.min(history_eval):\n",
    "      min_evalation_loss_in_el = eval_loss\n",
    "      min_total_loss_in_el = total_loss\n",
    "      min_evaluation_index = epoch+1\n",
    "      path = \"./model/lnn_ms_min_{}\".format(trial)\n",
    "      torch.save(l_nn.state_dict(), path)      \n",
    "  \n",
    "  print(\"{}/{} training loss:{},evaluation loss:{}\".format(epoch+1,num_epochs,total_loss,eval_loss))\n",
    "  print(\"When the training loss value is smallest: {}/{} min training loss:{}, min evalation loss:{}\".format(min_train_index,num_epochs,min_total_loss_in_tl,min_evaluation_loss_in_tl))\n",
    "  print(\"When the evaluation loss value is smallest: {}/{} min training loss:{}, min evalation loss:{}\".format(min_evaluation_index,num_epochs,min_total_loss_in_el,min_evalation_loss_in_el))\n",
    "  stats['train_loss'].append(total_loss)\n",
    "  stats['eval_loss'].append(eval_loss)\n",
    "  stats['computation_time'].append(time.time() - startt)\n",
    "\n",
    "print(\"train_loss:{}, std: {}\".format(np.mean(stats['train_loss']), np.std(stats['train_loss'])))\n",
    "print(\"test_loss:{}, std: {}\".format(np.mean(stats['eval_loss']), np.std(stats['eval_loss'])))\n",
    "print(\"computation_time:{}, std: {}\".format(np.mean(stats['computation_time']), np.std(stats['computation_time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.read_csv(\"./data/A.csv\", header=None, dtype=np.float32)\n",
    "B = pd.read_csv(\"./data/B.csv\", header=None, dtype=np.float32)\n",
    "A = np.mat(A)\n",
    "B = np.mat(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation\n",
    "# parameters\n",
    "k1 = 3.0\n",
    "k2 = 5.0\n",
    "m1 = 1.0\n",
    "m2 = 2.0\n",
    "l1 = 1.0\n",
    "l2 = 1.0\n",
    "eq_error = []\n",
    "net_error = []\n",
    "for trial in range(num_trials):\n",
    "  l_nn.load_state_dict(torch.load(\"./model/lnn_ms_min_{}\".format(trial), map_location=device))\n",
    "  l_nn.eval()\n",
    "  teval = torch.linspace(0.0,5.0,100)\n",
    "  #x0 = np.random.uniform(low=0.0, high=1.0, size=2)\n",
    "  #x0 = np.random.rand(4)\n",
    "  x0 = (0.91369884, 0.76173912, 0.7811432,  0.44947022)\n",
    "  print(x0)\n",
    "  dt = teval[1]-teval[0]\n",
    "  teval = teval.detach().cpu().numpy()\n",
    "  A = torch.tensor(A, dtype=torch.float32)\n",
    "  B = torch.tensor(B, dtype=torch.float32)\n",
    "  l_nn.eval()\n",
    "  l_nn.cpu()\n",
    "  def fvec_np(x,t):\n",
    "      tx = torch.tensor(x, dtype=torch.float).unsqueeze(0)\n",
    "      x = torch.matmul(tx, torch.inverse(B))\n",
    "      output = l_nn.forward(x).squeeze(0)\n",
    "      output = torch.matmul(A, output)\n",
    "      output = output.squeeze(0)\n",
    "      return output.detach().cpu().numpy() \n",
    "  res = scipy.integrate.odeint(fvec_np,x0,teval)\n",
    "\n",
    "  plt.plot(teval,res[:,0])\n",
    "  plt.plot(teval,res[:,1])\n",
    "  plt.plot(teval,res[:,2])\n",
    "  plt.plot(teval,res[:,3])\n",
    "  plt.show()\n",
    "    \n",
    "  # energy function\n",
    "  tres = torch.tensor(res, dtype=torch.float, requires_grad=True)\n",
    "  net_energy = l_nn.energy(torch.matmul(tres, torch.inverse(B)))\n",
    "  net_energy = net_energy.detach().cpu().numpy()\n",
    "  plt.plot(net_energy)\n",
    "  plt.show()\n",
    "  net_energy_error=net_energy[99]-net_energy[0]\n",
    "  print(\"energy error:{}\".format(net_energy_error))\n",
    "    \n",
    "  energy = np.square(res[:,2])/(2*m1) + np.square(res[:,3])/(2*m2) + k1*np.square((res[:,0]-l1))/2 + k2*np.square((res[:,1]-res[:,0]-l2))/2\n",
    "  energy_error=energy[99]-energy[0]\n",
    "  print(\"energy_error{}:{}\".format(trial,energy_error))\n",
    "  plt.plot(energy)\n",
    "  plt.show()\n",
    "\n",
    "  eq_error.append(energy_error)\n",
    "  net_error.append(net_energy_error)\n",
    "print(\"eq_error:{}\".format(eq_error),\"net_error:{}\".format(net_error))\n",
    "print(\"eq_error:{}, std: {}\".format(np.mean(np.abs(eq_error)), np.std(eq_error)))\n",
    "print(\"net_error:{}, std: {}\".format(np.mean(np.abs(net_error)), np.std(net_error)))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "# parameters\n",
    "k1 = 3.0\n",
    "k2 = 5.0\n",
    "m1 = 1.0\n",
    "m2 = 2.0\n",
    "l1 = 1.0\n",
    "l2 = 1.0\n",
    "# equations of motion\n",
    "def func(t, state):\n",
    "  dvdt = np.zeros_like(state)\n",
    "  dvdt[0] = state[2]\n",
    "  dvdt[1] = state[3]\n",
    "  dvdt[2] = (-k1*(state[0]-l1)+k2*(state[1]-state[0]-l2))/m1\n",
    "  dvdt[3] = -k2*(state[1]-state[0]-l2)/m2\n",
    "  return dvdt\n",
    "\n",
    "M = 100\n",
    "tend = 5.0\n",
    "t_eval = np.linspace(0,tend,M)\n",
    "dt = t_eval[1]-t_eval[0]\n",
    "\n",
    "x1_init = np.random.randn(1)\n",
    "x2_init = np.random.randn(1)\n",
    "#print(x1)\n",
    "v1_init = np.random.randn(1)\n",
    "v2_init = np.random.randn(1)\n",
    "state = []\n",
    "for i in range(1):\n",
    "  s = (0.91369884, 0.76173912, 0.7811432,  0.44947022)\n",
    "  state.append(s)\n",
    "p1 = []\n",
    "v1 = []\n",
    "p2 = []\n",
    "v2 = []\n",
    "flag = False\n",
    "for i in range(1):\n",
    "  sol = solver(func, [0, tend], state[i], t_eval=t_eval)\n",
    "  tval = sol['t']\n",
    "  dv1dt = sol['y'][0], sol['y'][1]\n",
    "  dv2dt = sol['y'][2], sol['y'][3]\n",
    "  p1 = dv1dt[0]\n",
    "  p2 = dv1dt[1]\n",
    "  v1 = dv2dt[0]\n",
    "  v2 = dv2dt[1]\n",
    "  plt.plot(tval, p1, 'steelblue')\n",
    "  plt.plot(tval, v1, 'g')\n",
    "  plt.plot(tval, p2, 'orange')\n",
    "  plt.plot(tval, v2, 'firebrick')\n",
    "  plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOCM/UxMrLKDbGBvwwJMQhV",
   "collapsed_sections": [],
   "name": "lnn (ms)(new)(min).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
