{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 29914,
     "status": "ok",
     "timestamp": 1621411010642,
     "user_tz": -540
    },
    "id": "bUtix5oO1hZa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.integrate\n",
    "from numpy import sin, cos\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "solver = scipy.integrate.solve_ivp\n",
    "\n",
    "\n",
    "seed = 3\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.determinstic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6811,
     "status": "ok",
     "timestamp": 1621411024929,
     "user_tz": -540
    },
    "id": "zNbE8mFW6lHD"
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "BATCH_size = 1000\n",
    "\n",
    "dftarget = pd.read_csv(\"./data/target.csv\", header=None, dtype=np.float32)\n",
    "dfinput = pd.read_csv(\"./data/input.csv\", header=None, dtype=np.float32)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(dfinput.values, dftarget.values, test_size=0.2)\n",
    "\n",
    "# train data\n",
    "data_train = data_utils.TensorDataset(torch.tensor(X_train), torch.tensor(Y_train))\n",
    "train_loader = torch.utils.data.DataLoader(data_train, batch_size=BATCH_size, shuffle=True)\n",
    "\n",
    "# test data\n",
    "data_test = data_utils.TensorDataset(torch.tensor(X_test), torch.tensor(Y_test))\n",
    "test_loader = torch.utils.data.DataLoader(data_test, batch_size=BATCH_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4732,
     "status": "ok",
     "timestamp": 1621411024930,
     "user_tz": -540
    },
    "id": "xdXd4_3_-nmQ"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9333,
     "status": "ok",
     "timestamp": 1621411030483,
     "user_tz": -540
    },
    "id": "-YlCua3H-qfx"
   },
   "outputs": [],
   "source": [
    "N = 2\n",
    "O = np.zeros((N,N))\n",
    "Id = np.eye(N)\n",
    "S = np.vstack([np.hstack([O,Id]),np.hstack([-Id,O])])\n",
    "St = torch.tensor(-S, dtype=torch.float32).to(device)\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self,input_size,hidden_size,output_size):\n",
    "    super(MLP,self).__init__()\n",
    "    self.l1 = nn.Linear(input_size,hidden_size)\n",
    "    self.l2 = nn.Linear(hidden_size,hidden_size)\n",
    "    self.l3 = nn.Linear(hidden_size,output_size)\n",
    "  \n",
    "  def forward(self,x):\n",
    "    x = self.l1(x)\n",
    "    x = torch.tanh(x)\n",
    "    x = self.l2(x)\n",
    "    x = torch.tanh(x)\n",
    "    x = self.l3(x)\n",
    "    return x\n",
    "\n",
    "  def grad(self,x):\n",
    "    x = x.requires_grad_(True)\n",
    "    with torch.enable_grad():\n",
    "      hamiltonian = self(x)\n",
    "      gradient = torch.autograd.grad(hamiltonian.sum(),x,create_graph=True,retain_graph=True)\n",
    "    return torch.matmul(gradient[0],St)\n",
    "\n",
    "  def fvec(self,t,x):\n",
    "    return self.grad(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8775,
     "status": "ok",
     "timestamp": 1621411030484,
     "user_tz": -540
    },
    "id": "d1Ev3hUN-uSp"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "input_size = 4\n",
    "output_size = 1\n",
    "hidden_size = 200\n",
    "num_trials = 10\n",
    "stats = {'train_loss': [], 'eval_loss': [], 'computation_time': []}\n",
    "\n",
    "for trial in range(num_trials):\n",
    "  mynet = MLP(input_size,hidden_size,output_size).to(device)\n",
    "  num_epochs = 2000\n",
    "\n",
    "  criterion = nn.MSELoss()\n",
    "\n",
    "  optimizer = optim.Adam(params=mynet.parameters(),lr=0.001)\n",
    "\n",
    "  history_loss = []\n",
    "  history_eval = []\n",
    "  history_acc = []\n",
    "\n",
    "  cnt = 0\n",
    "  startt = time.time()\n",
    "  for epoch in range(num_epochs):\n",
    "    mynet.train()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    eval_loss = 0.0\n",
    "    cnt = 0\n",
    "    for i,(data,target) in enumerate(train_loader):\n",
    "      optimizer.zero_grad()\n",
    "      output = mynet.grad(data.to(device))\n",
    "\n",
    "      loss = criterion(output,target.to(device))\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      total_loss = total_loss+loss.cpu().item()\n",
    "      cnt = cnt + 1\n",
    "    total_loss = total_loss/cnt\n",
    "\n",
    "    num_correct = 0\n",
    "    num_data = 0\n",
    "    mynet.eval()\n",
    "    eval_loss = 0.0\n",
    "    cnt = 0\n",
    "    for i,(data,target) in enumerate(test_loader):\n",
    "      output = mynet.grad(data.to(device))\n",
    "      eval_loss = eval_loss+criterion(output,target.to(device)).cpu().item()\n",
    "      cnt = cnt + 1\n",
    "    eval_loss = eval_loss/cnt\n",
    "  \n",
    "    history_loss.append(total_loss)\n",
    "    history_eval.append(eval_loss)\n",
    "\n",
    "  \n",
    "  print(\"{}/{} training loss:{},evaluation loss:{}\".format(epoch+1,num_epochs,total_loss,eval_loss))\n",
    "  path = \"./model/hnn_ms_{}\".format(trial)\n",
    "  torch.save(mynet.state_dict(), path)\n",
    "  stats['train_loss'].append(total_loss)\n",
    "  stats['eval_loss'].append(eval_loss)\n",
    "  stats['computation_time'].append(time.time() - startt)\n",
    "\n",
    "print(\"train_loss:{}, std: {}\".format(np.mean(stats['train_loss']), np.std(stats['train_loss'])))\n",
    "print(\"test_loss:{}, std: {}\".format(np.mean(stats['eval_loss']), np.std(stats['eval_loss'])))\n",
    "print(\"computation_time:{}, std: {}\".format(np.mean(stats['computation_time']), np.std(stats['computation_time'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.read_csv(\"./data/A.csv\", header=None, dtype=np.float32)\n",
    "B = pd.read_csv(\"./data/B.csv\", header=None, dtype=np.float32)\n",
    "A = np.mat(A)\n",
    "B = np.mat(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation\n",
    "# parameters\n",
    "k1 = 3.0\n",
    "k2 = 5.0\n",
    "m1 = 1.0\n",
    "m2 = 2.0\n",
    "l1 = 1.0\n",
    "l2 = 1.0\n",
    "eq_error = []\n",
    "net_error = []\n",
    "for trial in range(num_trials):\n",
    "  mynet.load_state_dict(torch.load(\"./model/hnn_ms_{}\".format(trial), map_location=\"cpu\"))\n",
    "  mynet.eval()\n",
    "  teval = torch.linspace(0.0,5.0,100)\n",
    "  x0 = np.random.rand(4)\n",
    "  #x0 = (0.91369884, 0.76173912, 0.7811432,  0.44947022)\n",
    "  \n",
    "  print(x0)\n",
    "  dt = teval[1]-teval[0]\n",
    "  St = torch.tensor(-S, dtype=torch.float32)\n",
    "  teval = teval.detach().cpu().numpy()\n",
    "  A = torch.tensor(A, dtype=torch.float32)\n",
    "  B = torch.tensor(B, dtype=torch.float32)\n",
    "  mynet.eval()\n",
    "  mynet.cpu()\n",
    "  def fvec_np(x,t):\n",
    "    tx = torch.tensor(x, dtype=torch.float)\n",
    "    x = torch.matmul(tx, torch.inverse(B))\n",
    "    output = mynet.grad(x).squeeze(0)\n",
    "    output = torch.matmul(A, output)\n",
    "    output = output.squeeze(0)    \n",
    "    return output.detach().cpu().numpy()\n",
    "\n",
    "  res = scipy.integrate.odeint(fvec_np,x0,teval)\n",
    "\n",
    "  plt.plot(teval,res[:,0])\n",
    "  plt.plot(teval,res[:,1])\n",
    "  plt.plot(teval,res[:,2])\n",
    "  plt.plot(teval,res[:,3])\n",
    "  plt.show()\n",
    "  def net_energy(x,t):\n",
    "    tx = torch.tensor(x, dtype=torch.float)\n",
    "    x = torch.matmul(tx, torch.inverse(B))\n",
    "    ne = mynet.forward(x).squeeze(0)\n",
    "    return ne.detach().cpu().numpy()\n",
    "\n",
    "  net_energy = net_energy(res, teval).reshape((100))\n",
    "  plt.plot(teval,net_energy)\n",
    "  plt.show()\n",
    "  net_energy_error=net_energy[99]-net_energy[0]\n",
    "  print(\"energy_error{}:{}\".format(trial,net_energy_error))\n",
    "    \n",
    "  energy = np.square(res[:,2])/(2*m1) + np.square(res[:,3])/(2*m2) + k1*np.square((res[:,0]-l1))/2 + k2*np.square((res[:,1]-res[:,0]-l2))/2\n",
    "  energy_error=energy[99]-energy[0]\n",
    "  print(\"energy_error{}:{}\".format(trial,energy_error))\n",
    "  plt.plot(energy)\n",
    "  plt.show()\n",
    "\n",
    "  eq_error.append(energy_error)\n",
    "  net_error.append(net_energy_error)\n",
    "print(\"eq_error:{}\".format(eq_error),\"net_error:{}\".format(net_error))\n",
    "print(\"eq_error:{}, std: {}\".format(np.mean(np.abs(eq_error)), np.std(eq_error)))\n",
    "print(\"net_error:{}, std: {}\".format(np.mean(np.abs(net_error)), np.std(net_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "# parameters\n",
    "k1 = 3.0\n",
    "k2 = 5.0\n",
    "m1 = 1.0\n",
    "m2 = 2.0\n",
    "l1 = 1.0\n",
    "l2 = 1.0\n",
    "# equations of motion\n",
    "def func(t, state):\n",
    "  dvdt = np.zeros_like(state)\n",
    "  dvdt[0] = state[2]\n",
    "  dvdt[1] = state[3]\n",
    "  dvdt[2] = (-k1*(state[0]-l1)+k2*(state[1]-state[0]-l2))/m1\n",
    "  dvdt[3] = -k2*(state[1]-state[0]-l2)/m2\n",
    "  return dvdt\n",
    "\n",
    "M = 100\n",
    "tend = 5.0\n",
    "t_eval = np.linspace(0,tend,M)\n",
    "dt = t_eval[1]-t_eval[0]\n",
    "\n",
    "x1_init = np.random.randn(1)\n",
    "x2_init = np.random.randn(1)\n",
    "#print(x1)\n",
    "v1_init = np.random.randn(1)\n",
    "v2_init = np.random.randn(1)\n",
    "state = []\n",
    "for i in range(1):\n",
    "  s = (0.91369884, 0.76173912, 0.7811432,  0.44947022)\n",
    "  state.append(s)\n",
    "p1 = []\n",
    "v1 = []\n",
    "p2 = []\n",
    "v2 = []\n",
    "flag = False\n",
    "for i in range(1):\n",
    "  sol = solver(func, [0, tend], state[i], t_eval=t_eval)\n",
    "  tval = sol['t']\n",
    "  dv1dt = sol['y'][0], sol['y'][1]\n",
    "  dv2dt = sol['y'][2], sol['y'][3]\n",
    "  p1 = dv1dt[0]\n",
    "  p2 = dv1dt[1] \n",
    "  v1 = dv2dt[0]\n",
    "  v2 = dv2dt[1]\n",
    "  plt.plot(tval, p1, 'steelblue')\n",
    "  plt.plot(tval, v1, 'g')\n",
    "  plt.plot(tval, p2, 'orange')\n",
    "  plt.plot(tval, v2, 'firebrick')\n",
    "  plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNUqIJvMl73dXwd1+hNrzUa",
   "name": "hnn (ms)(new).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
